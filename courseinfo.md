---
layout: page
title: Course Info
description: >-
    Course policies and information.
---

# About
{:.no_toc}

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Commentary

Participants will learn knowledge on neuron models, synapse models, neural network models, working memory and decision models, neural coding and decoding, Bayesian inference network, and neural network based learning algorithms in this course.  

## Objectives

After finishing this course, participants are expected to own the ability to 
- computationally simulate the neural system working mechanism
- apply brain-inspired algorithms (e.g. supervised, and unsupervised neural networks, and reinforcement learning)

## Prerequisites

- Knowledge on differential equations
- Ability to write non-trivial programmes

## Grading

### Project I (50%)

TBA

### Project II (50%)

TBA

## Lecture

Lectures are given by Prof. Dahui Wang and Prof. Bailu Si jointly. For detailed information, see [Syllabus](https://bnucns.github.io/syllabus/) and [Schedule](https://bnucns.github.io/schedule/)

## References

```bibtex
@book{dayan2001theoretical,
  title={Theoretical neuroscience: computational and mathematical modeling of neural systems},
  author={Dayan, Peter and Abbott, Laurence F},
  year={2001},
  publisher={Computational Neuroscience Series}
}

@book{izhikevich2007dynamical,
  title={Dynamical systems in neuroscience},
  author={Izhikevich, Eugene M},
  year={2007},
  publisher={MIT press}
}

@book{gerstner2014neuronal,
  title={Neuronal dynamics: From single neurons to networks and models of cognition},
  author={Gerstner, Wulfram and Kistler, Werner M and Naud, Richard and Paninski, Liam},
  year={2014},
  publisher={Cambridge University Press}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}
```

